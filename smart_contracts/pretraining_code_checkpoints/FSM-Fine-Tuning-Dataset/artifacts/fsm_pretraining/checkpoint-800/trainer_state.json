{
  "best_global_step": 800,
  "best_metric": 0.0005534329684451222,
  "best_model_checkpoint": "/Users/chunghyunhan/Projects/agentics_smartcontract/Agentics/FSM-Fine-Tuning-Dataset/artifacts/fsm_pretraining/checkpoint-800",
  "epoch": 0.44992794122816265,
  "eval_steps": 50,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005624099265352033,
      "grad_norm": 0.7047237753868103,
      "learning_rate": 6.741573033707865e-07,
      "loss": 2.0435,
      "step": 10
    },
    {
      "epoch": 0.011248198530704067,
      "grad_norm": 0.7033442258834839,
      "learning_rate": 1.4232209737827715e-06,
      "loss": 2.0412,
      "step": 20
    },
    {
      "epoch": 0.0168722977960561,
      "grad_norm": 0.6994844079017639,
      "learning_rate": 2.1722846441947567e-06,
      "loss": 2.0361,
      "step": 30
    },
    {
      "epoch": 0.022496397061408133,
      "grad_norm": 0.6995497941970825,
      "learning_rate": 2.9213483146067416e-06,
      "loss": 2.0283,
      "step": 40
    },
    {
      "epoch": 0.028120496326760166,
      "grad_norm": 0.7006962299346924,
      "learning_rate": 3.670411985018727e-06,
      "loss": 2.0174,
      "step": 50
    },
    {
      "epoch": 0.028120496326760166,
      "eval_loss": 2.0101659297943115,
      "eval_runtime": 2822.0973,
      "eval_samples_per_second": 1.12,
      "eval_steps_per_second": 1.12,
      "step": 50
    },
    {
      "epoch": 0.0337445955921122,
      "grad_norm": 0.7022277116775513,
      "learning_rate": 4.419475655430712e-06,
      "loss": 2.0031,
      "step": 60
    },
    {
      "epoch": 0.039368694857464234,
      "grad_norm": 0.7091774344444275,
      "learning_rate": 5.168539325842698e-06,
      "loss": 1.9849,
      "step": 70
    },
    {
      "epoch": 0.04499279412281627,
      "grad_norm": 0.7136750221252441,
      "learning_rate": 5.917602996254682e-06,
      "loss": 1.9618,
      "step": 80
    },
    {
      "epoch": 0.0506168933881683,
      "grad_norm": 0.727027177810669,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.9329,
      "step": 90
    },
    {
      "epoch": 0.05624099265352033,
      "grad_norm": 0.7335322499275208,
      "learning_rate": 7.415730337078652e-06,
      "loss": 1.897,
      "step": 100
    },
    {
      "epoch": 0.05624099265352033,
      "eval_loss": 1.8742681741714478,
      "eval_runtime": 2798.7876,
      "eval_samples_per_second": 1.129,
      "eval_steps_per_second": 1.129,
      "step": 100
    },
    {
      "epoch": 0.06186509191887237,
      "grad_norm": 0.746709406375885,
      "learning_rate": 8.164794007490638e-06,
      "loss": 1.8529,
      "step": 110
    },
    {
      "epoch": 0.0674891911842244,
      "grad_norm": 0.7580017447471619,
      "learning_rate": 8.913857677902621e-06,
      "loss": 1.799,
      "step": 120
    },
    {
      "epoch": 0.07311329044957643,
      "grad_norm": 0.7777360081672668,
      "learning_rate": 9.662921348314608e-06,
      "loss": 1.7338,
      "step": 130
    },
    {
      "epoch": 0.07873738971492847,
      "grad_norm": 0.8196716904640198,
      "learning_rate": 1.0411985018726594e-05,
      "loss": 1.6554,
      "step": 140
    },
    {
      "epoch": 0.08436148898028051,
      "grad_norm": 0.8875933885574341,
      "learning_rate": 1.1161048689138579e-05,
      "loss": 1.5601,
      "step": 150
    },
    {
      "epoch": 0.08436148898028051,
      "eval_loss": 1.499356985092163,
      "eval_runtime": 2810.0933,
      "eval_samples_per_second": 1.125,
      "eval_steps_per_second": 1.125,
      "step": 150
    },
    {
      "epoch": 0.08998558824563253,
      "grad_norm": 0.9873078465461731,
      "learning_rate": 1.1910112359550562e-05,
      "loss": 1.4419,
      "step": 160
    },
    {
      "epoch": 0.09560968751098457,
      "grad_norm": 1.1212918758392334,
      "learning_rate": 1.2659176029962547e-05,
      "loss": 1.2924,
      "step": 170
    },
    {
      "epoch": 0.1012337867763366,
      "grad_norm": 1.2692413330078125,
      "learning_rate": 1.3408239700374532e-05,
      "loss": 1.1071,
      "step": 180
    },
    {
      "epoch": 0.10685788604168864,
      "grad_norm": 1.4707680940628052,
      "learning_rate": 1.4157303370786517e-05,
      "loss": 0.8893,
      "step": 190
    },
    {
      "epoch": 0.11248198530704066,
      "grad_norm": 1.5528134107589722,
      "learning_rate": 1.4906367041198503e-05,
      "loss": 0.6531,
      "step": 200
    },
    {
      "epoch": 0.11248198530704066,
      "eval_loss": 0.5270661115646362,
      "eval_runtime": 2800.2964,
      "eval_samples_per_second": 1.129,
      "eval_steps_per_second": 1.129,
      "step": 200
    },
    {
      "epoch": 0.1181060845723927,
      "grad_norm": 1.2084779739379883,
      "learning_rate": 1.565543071161049e-05,
      "loss": 0.4393,
      "step": 210
    },
    {
      "epoch": 0.12373018383774474,
      "grad_norm": 0.8955487608909607,
      "learning_rate": 1.6404494382022473e-05,
      "loss": 0.2744,
      "step": 220
    },
    {
      "epoch": 0.12935428310309677,
      "grad_norm": 0.7902238965034485,
      "learning_rate": 1.715355805243446e-05,
      "loss": 0.1615,
      "step": 230
    },
    {
      "epoch": 0.1349783823684488,
      "grad_norm": 0.5778536796569824,
      "learning_rate": 1.7902621722846443e-05,
      "loss": 0.0842,
      "step": 240
    },
    {
      "epoch": 0.14060248163380085,
      "grad_norm": 0.2846051752567291,
      "learning_rate": 1.8651685393258426e-05,
      "loss": 0.0386,
      "step": 250
    },
    {
      "epoch": 0.14060248163380085,
      "eval_loss": 0.02573332190513611,
      "eval_runtime": 2810.1186,
      "eval_samples_per_second": 1.125,
      "eval_steps_per_second": 1.125,
      "step": 250
    },
    {
      "epoch": 0.14622658089915286,
      "grad_norm": 0.1526128053665161,
      "learning_rate": 1.9400749063670416e-05,
      "loss": 0.0208,
      "step": 260
    },
    {
      "epoch": 0.1518506801645049,
      "grad_norm": 0.08570992946624756,
      "learning_rate": 1.9992110453648917e-05,
      "loss": 0.0144,
      "step": 270
    },
    {
      "epoch": 0.15747477942985694,
      "grad_norm": 0.06315194070339203,
      "learning_rate": 1.995266272189349e-05,
      "loss": 0.0116,
      "step": 280
    },
    {
      "epoch": 0.16309887869520898,
      "grad_norm": 0.05501817166805267,
      "learning_rate": 1.991321499013807e-05,
      "loss": 0.0099,
      "step": 290
    },
    {
      "epoch": 0.16872297796056102,
      "grad_norm": 0.04928300157189369,
      "learning_rate": 1.9873767258382643e-05,
      "loss": 0.0087,
      "step": 300
    },
    {
      "epoch": 0.16872297796056102,
      "eval_loss": 0.008022606372833252,
      "eval_runtime": 2830.9406,
      "eval_samples_per_second": 1.117,
      "eval_steps_per_second": 1.117,
      "step": 300
    },
    {
      "epoch": 0.17434707722591303,
      "grad_norm": 0.046393584460020065,
      "learning_rate": 1.983431952662722e-05,
      "loss": 0.0076,
      "step": 310
    },
    {
      "epoch": 0.17997117649126507,
      "grad_norm": 0.04341750591993332,
      "learning_rate": 1.9794871794871798e-05,
      "loss": 0.0067,
      "step": 320
    },
    {
      "epoch": 0.1855952757566171,
      "grad_norm": 0.04226469248533249,
      "learning_rate": 1.975542406311637e-05,
      "loss": 0.0058,
      "step": 330
    },
    {
      "epoch": 0.19121937502196915,
      "grad_norm": 0.03892131894826889,
      "learning_rate": 1.971597633136095e-05,
      "loss": 0.005,
      "step": 340
    },
    {
      "epoch": 0.19684347428732116,
      "grad_norm": 0.03577360510826111,
      "learning_rate": 1.9676528599605523e-05,
      "loss": 0.0044,
      "step": 350
    },
    {
      "epoch": 0.19684347428732116,
      "eval_loss": 0.003987445496022701,
      "eval_runtime": 2805.6833,
      "eval_samples_per_second": 1.127,
      "eval_steps_per_second": 1.127,
      "step": 350
    },
    {
      "epoch": 0.2024675735526732,
      "grad_norm": 0.032088760286569595,
      "learning_rate": 1.96370808678501e-05,
      "loss": 0.0038,
      "step": 360
    },
    {
      "epoch": 0.20809167281802524,
      "grad_norm": 0.028491897508502007,
      "learning_rate": 1.9597633136094675e-05,
      "loss": 0.0033,
      "step": 370
    },
    {
      "epoch": 0.21371577208337728,
      "grad_norm": 0.026376547291874886,
      "learning_rate": 1.9558185404339252e-05,
      "loss": 0.0029,
      "step": 380
    },
    {
      "epoch": 0.21933987134872932,
      "grad_norm": 0.021982155740261078,
      "learning_rate": 1.9518737672583826e-05,
      "loss": 0.0026,
      "step": 390
    },
    {
      "epoch": 0.22496397061408133,
      "grad_norm": 0.01931956596672535,
      "learning_rate": 1.9479289940828404e-05,
      "loss": 0.0024,
      "step": 400
    },
    {
      "epoch": 0.22496397061408133,
      "eval_loss": 0.002213079482316971,
      "eval_runtime": 2830.7396,
      "eval_samples_per_second": 1.117,
      "eval_steps_per_second": 1.117,
      "step": 400
    },
    {
      "epoch": 0.23058806987943337,
      "grad_norm": 0.01749786175787449,
      "learning_rate": 1.9439842209072978e-05,
      "loss": 0.0022,
      "step": 410
    },
    {
      "epoch": 0.2362121691447854,
      "grad_norm": 0.01609753631055355,
      "learning_rate": 1.9400394477317555e-05,
      "loss": 0.002,
      "step": 420
    },
    {
      "epoch": 0.24183626841013744,
      "grad_norm": 0.014760036952793598,
      "learning_rate": 1.9360946745562133e-05,
      "loss": 0.0019,
      "step": 430
    },
    {
      "epoch": 0.24746036767548948,
      "grad_norm": 0.01427557971328497,
      "learning_rate": 1.9321499013806707e-05,
      "loss": 0.0018,
      "step": 440
    },
    {
      "epoch": 0.2530844669408415,
      "grad_norm": 0.013075917959213257,
      "learning_rate": 1.9282051282051284e-05,
      "loss": 0.0017,
      "step": 450
    },
    {
      "epoch": 0.2530844669408415,
      "eval_loss": 0.0016023970674723387,
      "eval_runtime": 2806.4311,
      "eval_samples_per_second": 1.126,
      "eval_steps_per_second": 1.126,
      "step": 450
    },
    {
      "epoch": 0.25870856620619354,
      "grad_norm": 0.019401011988520622,
      "learning_rate": 1.9242603550295858e-05,
      "loss": 0.0016,
      "step": 460
    },
    {
      "epoch": 0.26433266547154555,
      "grad_norm": 0.011816035956144333,
      "learning_rate": 1.9203155818540436e-05,
      "loss": 0.0015,
      "step": 470
    },
    {
      "epoch": 0.2699567647368976,
      "grad_norm": 0.011105356737971306,
      "learning_rate": 1.916370808678501e-05,
      "loss": 0.0014,
      "step": 480
    },
    {
      "epoch": 0.2755808640022496,
      "grad_norm": 0.010411798022687435,
      "learning_rate": 1.9124260355029587e-05,
      "loss": 0.0014,
      "step": 490
    },
    {
      "epoch": 0.2812049632676017,
      "grad_norm": 0.009950041770935059,
      "learning_rate": 1.908481262327416e-05,
      "loss": 0.0013,
      "step": 500
    },
    {
      "epoch": 0.2812049632676017,
      "eval_loss": 0.0012733740732073784,
      "eval_runtime": 2811.6735,
      "eval_samples_per_second": 1.124,
      "eval_steps_per_second": 1.124,
      "step": 500
    },
    {
      "epoch": 0.2868290625329537,
      "grad_norm": 0.00952255167067051,
      "learning_rate": 1.904536489151874e-05,
      "loss": 0.0013,
      "step": 510
    },
    {
      "epoch": 0.2924531617983057,
      "grad_norm": 0.009084169752895832,
      "learning_rate": 1.9005917159763313e-05,
      "loss": 0.0012,
      "step": 520
    },
    {
      "epoch": 0.2980772610636578,
      "grad_norm": 0.008827236481010914,
      "learning_rate": 1.8966469428007894e-05,
      "loss": 0.0012,
      "step": 530
    },
    {
      "epoch": 0.3037013603290098,
      "grad_norm": 0.008537046611309052,
      "learning_rate": 1.8927021696252468e-05,
      "loss": 0.0011,
      "step": 540
    },
    {
      "epoch": 0.30932545959436186,
      "grad_norm": 0.008033516816794872,
      "learning_rate": 1.8887573964497045e-05,
      "loss": 0.0011,
      "step": 550
    },
    {
      "epoch": 0.30932545959436186,
      "eval_loss": 0.0010562707902863622,
      "eval_runtime": 2824.1062,
      "eval_samples_per_second": 1.119,
      "eval_steps_per_second": 1.119,
      "step": 550
    },
    {
      "epoch": 0.3149495588597139,
      "grad_norm": 0.007866323925554752,
      "learning_rate": 1.884812623274162e-05,
      "loss": 0.0011,
      "step": 560
    },
    {
      "epoch": 0.3205736581250659,
      "grad_norm": 0.007628380786627531,
      "learning_rate": 1.8808678500986197e-05,
      "loss": 0.001,
      "step": 570
    },
    {
      "epoch": 0.32619775739041795,
      "grad_norm": 0.007450282573699951,
      "learning_rate": 1.876923076923077e-05,
      "loss": 0.001,
      "step": 580
    },
    {
      "epoch": 0.33182185665576996,
      "grad_norm": 0.007137711625546217,
      "learning_rate": 1.8729783037475348e-05,
      "loss": 0.001,
      "step": 590
    },
    {
      "epoch": 0.33744595592112203,
      "grad_norm": 0.006859909277409315,
      "learning_rate": 1.8690335305719922e-05,
      "loss": 0.0009,
      "step": 600
    },
    {
      "epoch": 0.33744595592112203,
      "eval_loss": 0.0009000962600111961,
      "eval_runtime": 2805.5365,
      "eval_samples_per_second": 1.127,
      "eval_steps_per_second": 1.127,
      "step": 600
    },
    {
      "epoch": 0.34307005518647404,
      "grad_norm": 0.0066762338392436504,
      "learning_rate": 1.8650887573964496e-05,
      "loss": 0.0009,
      "step": 610
    },
    {
      "epoch": 0.34869415445182605,
      "grad_norm": 0.006548501551151276,
      "learning_rate": 1.8611439842209074e-05,
      "loss": 0.0009,
      "step": 620
    },
    {
      "epoch": 0.3543182537171781,
      "grad_norm": 0.006305139511823654,
      "learning_rate": 1.8571992110453648e-05,
      "loss": 0.0009,
      "step": 630
    },
    {
      "epoch": 0.35994235298253013,
      "grad_norm": 0.006384340580552816,
      "learning_rate": 1.853254437869823e-05,
      "loss": 0.0008,
      "step": 640
    },
    {
      "epoch": 0.3655664522478822,
      "grad_norm": 0.005929171107709408,
      "learning_rate": 1.8493096646942803e-05,
      "loss": 0.0008,
      "step": 650
    },
    {
      "epoch": 0.3655664522478822,
      "eval_loss": 0.0007819244056008756,
      "eval_runtime": 2803.8413,
      "eval_samples_per_second": 1.127,
      "eval_steps_per_second": 1.127,
      "step": 650
    },
    {
      "epoch": 0.3711905515132342,
      "grad_norm": 0.0057265679351985455,
      "learning_rate": 1.845364891518738e-05,
      "loss": 0.0008,
      "step": 660
    },
    {
      "epoch": 0.3768146507785862,
      "grad_norm": 0.005807825364172459,
      "learning_rate": 1.8414201183431954e-05,
      "loss": 0.0008,
      "step": 670
    },
    {
      "epoch": 0.3824387500439383,
      "grad_norm": 0.005403839983046055,
      "learning_rate": 1.837475345167653e-05,
      "loss": 0.0007,
      "step": 680
    },
    {
      "epoch": 0.3880628493092903,
      "grad_norm": 0.005280022509396076,
      "learning_rate": 1.8335305719921106e-05,
      "loss": 0.0007,
      "step": 690
    },
    {
      "epoch": 0.3936869485746423,
      "grad_norm": 0.005109887570142746,
      "learning_rate": 1.8295857988165683e-05,
      "loss": 0.0007,
      "step": 700
    },
    {
      "epoch": 0.3936869485746423,
      "eval_loss": 0.0006892607198096812,
      "eval_runtime": 2816.6818,
      "eval_samples_per_second": 1.122,
      "eval_steps_per_second": 1.122,
      "step": 700
    },
    {
      "epoch": 0.3993110478399944,
      "grad_norm": 0.004967401269823313,
      "learning_rate": 1.8256410256410257e-05,
      "loss": 0.0007,
      "step": 710
    },
    {
      "epoch": 0.4049351471053464,
      "grad_norm": 0.005202935077250004,
      "learning_rate": 1.8216962524654835e-05,
      "loss": 0.0007,
      "step": 720
    },
    {
      "epoch": 0.41055924637069846,
      "grad_norm": 0.004751513246446848,
      "learning_rate": 1.817751479289941e-05,
      "loss": 0.0007,
      "step": 730
    },
    {
      "epoch": 0.4161833456360505,
      "grad_norm": 0.004781910218298435,
      "learning_rate": 1.8138067061143986e-05,
      "loss": 0.0006,
      "step": 740
    },
    {
      "epoch": 0.4218074449014025,
      "grad_norm": 0.004621007479727268,
      "learning_rate": 1.8098619329388564e-05,
      "loss": 0.0006,
      "step": 750
    },
    {
      "epoch": 0.4218074449014025,
      "eval_loss": 0.0006146691739559174,
      "eval_runtime": 2820.8278,
      "eval_samples_per_second": 1.121,
      "eval_steps_per_second": 1.121,
      "step": 750
    },
    {
      "epoch": 0.42743154416675455,
      "grad_norm": 0.004504826385527849,
      "learning_rate": 1.8059171597633138e-05,
      "loss": 0.0006,
      "step": 760
    },
    {
      "epoch": 0.43305564343210656,
      "grad_norm": 0.004567735828459263,
      "learning_rate": 1.8019723865877715e-05,
      "loss": 0.0006,
      "step": 770
    },
    {
      "epoch": 0.43867974269745863,
      "grad_norm": 0.004555413965135813,
      "learning_rate": 1.798027613412229e-05,
      "loss": 0.0006,
      "step": 780
    },
    {
      "epoch": 0.44430384196281064,
      "grad_norm": 0.00424960907548666,
      "learning_rate": 1.7940828402366867e-05,
      "loss": 0.0006,
      "step": 790
    },
    {
      "epoch": 0.44992794122816265,
      "grad_norm": 0.004223318304866552,
      "learning_rate": 1.790138067061144e-05,
      "loss": 0.0006,
      "step": 800
    },
    {
      "epoch": 0.44992794122816265,
      "eval_loss": 0.0005534329684451222,
      "eval_runtime": 2816.8475,
      "eval_samples_per_second": 1.122,
      "eval_steps_per_second": 1.122,
      "step": 800
    }
  ],
  "logging_steps": 10,
  "max_steps": 5337,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.17116991193088e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
